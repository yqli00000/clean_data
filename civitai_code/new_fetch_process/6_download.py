import json
import os
import requests
import time
import random
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
from urllib.parse import urlparse
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
                           
# ================= é…ç½®åŒºåŸŸ =================
INPUT_FILE = r"F:\civitai_new_fetch\summary\final_clean_model_checkpoint_dataset.jsonl"      # è¾“å…¥æ–‡ä»¶
OUTPUT_ROOT = r"F:\civitai_new_fetch\images"           # æ ¹å­˜å‚¨ç›®å½•
MAX_WORKERS = 8                             # å¹¶å‘çº¿ç¨‹æ•°
TIMEOUT = 30                                 # è¶…æ—¶æ—¶é—´
# 3. è®¾ç½®ä»£ç† (ã€é‡è¦ã€‘å¦‚æœä½ åœ¨å›½å†…ï¼Œå¿…é¡»é…ç½®è¿™ä¸ª)
# å¦‚æœä½ æ²¡æœ‰ä»£ç†ï¼Œè¯·æŠŠä¸‹é¢è®¾ä¸º Noneï¼Œå³: PROXIES = None
PROXIES = {
    "http": "http://127.0.0.1:7890",   # ğŸ‘ˆ è¯·å°† 7890 æ”¹ä¸ºä½ çš„ä»£ç†ç«¯å£
    "https": "http://127.0.0.1:7890"   # ğŸ‘ˆ è¯·å°† 7890 æ”¹ä¸ºä½ çš„ä»£ç†ç«¯å£
}
# ==========================================================

def get_session():
    """åˆ›å»ºä¸€ä¸ªå¸¦æœ‰é‡è¯•æœºåˆ¶çš„ Session"""
    session = requests.Session()
    
    # é‡è¯•ç­–ç•¥: å¤±è´¥åé‡è¯• 3 æ¬¡ï¼Œé—´éš”æ—¶é—´é€’å¢ (backoff_factor)
    # status_forcelist: é‡åˆ° 500, 502, 503, 504, 429 é”™è¯¯æ—¶é‡è¯•
    retries = Retry(total=3, backoff_factor=1, status_forcelist=[500, 502, 503, 504, 429])
    
    adapter = HTTPAdapter(max_retries=retries)
    session.mount('http://', adapter)
    session.mount('https://', adapter)
    session.proxies = PROXIES if PROXIES else {}
    return session

def get_extension_from_url(url):
    try:
        parsed = urlparse(url)
        path = parsed.path
        ext = os.path.splitext(path)[1]
        if ext.lower() in ['.jpg', '.jpeg', '.png', '.webp', '.gif']:
            return ext
    except:
        pass
    return ".jpeg"

def calculate_storage_path(image_id):
    s_id = str(image_id).zfill(4)
    last_4 = s_id[-4:]
    thousand_digit = s_id[-4]
    return os.path.join(OUTPUT_ROOT, thousand_digit, last_4)

def process_item(data, session):
    image_id = data.get('id')
    image_url = data.get('url')
    
    if not image_id or not image_url: return "MissingInfo"

    try:
        save_dir = calculate_storage_path(image_id)
        if not os.path.exists(save_dir):
            os.makedirs(save_dir, exist_ok=True)

        ext = get_extension_from_url(image_url)
        img_path = os.path.join(save_dir, f"{image_id}{ext}")
        json_path = os.path.join(save_dir, f"{image_id}.json")

        # ä¿å­˜ JSON
        if not os.path.exists(json_path):
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

        # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦å·²å­˜åœ¨ä¸”å®Œæ•´
        if os.path.exists(img_path) and os.path.getsize(img_path) > 100: # å¤§äº100å­—èŠ‚ç®—æœ‰æ•ˆ
            return "Skipped"

        # === æ ¸å¿ƒä¸‹è½½é€»è¾‘ ===
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36",
            "Referer": "https://civitai.com/"
        }
        
        # ä½¿ç”¨ä¼ å…¥çš„ session (åŒ…å«ä»£ç†å’Œé‡è¯•)
        with session.get(image_url, headers=headers, stream=True, timeout=TIMEOUT) as response:
            if response.status_code == 200:
                with open(img_path, 'wb') as f:
                    for chunk in response.iter_content(4096):
                        f.write(chunk)
                return "Success"
            elif response.status_code == 404:
                return "Error_404_NotFound"
            elif response.status_code == 403:
                return "Error_403_Forbidden"
            else:
                return f"Error_{response.status_code}"

    except requests.exceptions.ProxyError:
        return "ProxyError"
    except requests.exceptions.ConnectTimeout:
        return "Timeout"
    except Exception as e:
        return f"Exception_{str(e)[:20]}"

def main():
    if not os.path.exists(INPUT_FILE):
        print("âŒ æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶")
        return

    # 1. ç­›é€‰å‡ºæ‰€æœ‰éœ€è¦ä¸‹è½½çš„ä»»åŠ¡
    print("ğŸ“– è¯»å–ä»»åŠ¡ä¸­...")
    tasks = []
    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                try:
                    d = json.loads(line)
                    if d.get('type') == 'image': tasks.append(d)
                except: pass

    # è¿‡æ»¤æ‰å·²ç»ä¸‹è½½æˆåŠŸçš„ï¼ˆç®€å•é¢„æ£€æŸ¥ï¼ŒåŠ å¿«å¯åŠ¨é€Ÿåº¦ï¼‰
    # å¦‚æœä½ ç¡®å®šä¹‹å‰çš„ä¸‹è½½æ²¡é—®é¢˜ï¼Œå¯ä»¥å¼€å¯è¿™ä¸ªé¢„æ£€æŸ¥é€»è¾‘ï¼Œå¦åˆ™æ³¨é‡Šæ‰
    # print("ğŸ” é¢„æ£€æŸ¥å·²å®Œæˆçš„æ–‡ä»¶...")
    # final_tasks = []
    # for t in tasks:
    #     sid = str(t['id']).zfill(4)
    #     path = os.path.join(OUTPUT_ROOT, sid[-4], sid[-4:], f"{t['id']}.jpeg") # å‡å®šæ˜¯jpeg
    #     if not os.path.exists(path): # è¿™é‡Œåªæ˜¯ç²—ç•¥æ£€æŸ¥
    #         final_tasks.append(t)
    # tasks = final_tasks

    print(f"ğŸš€ å¼€å§‹ä¸‹è½½ {len(tasks)} å¼ å›¾ç‰‡")
    print(f"ğŸ”Œ ä»£ç†è®¾ç½®: {PROXIES if PROXIES else 'æ—  (ç›´è¿)'}")
    print(f"ğŸ§µ çº¿ç¨‹æ•°: {MAX_WORKERS}")

    stats = {"Success": 0, "Skipped": 0, "Failed": 0, "Errors": {}}

    # åˆ›å»ºä¸€ä¸ªçº¿ç¨‹å®‰å…¨çš„ Session å·¥å‚
    # æ³¨æ„ï¼šrequests.Session ä¸æ˜¯çº¿ç¨‹å®‰å…¨çš„ï¼Œä½†åœ¨ ThreadPoolExecutor é‡Œ
    # æˆ‘ä»¬é€šå¸¸ä¸ºæ¯ä¸ªçº¿ç¨‹æˆ–æ¯æ¬¡è¯·æ±‚å»ºç«‹è¿æ¥ï¼Œæˆ–è€…å°å¿ƒä½¿ç”¨ã€‚
    # ä¸ºäº†ç®€å•ç¨³å¦¥ï¼Œæˆ‘ä»¬åœ¨ process_item å¤–éƒ¨ä¸å…±äº« sessionï¼Œ
    # ä½†ä¸ºäº†å¤ç”¨è¿æ¥ï¼Œæˆ‘ä»¬å¯ä»¥è®©æ¯ä¸ªçº¿ç¨‹æ‹¥æœ‰ä¸€ä¸ª session (è¿™é‡Œç®€åŒ–ä¸ºæ¯æ¬¡è¯·æ±‚æ–°å»ºå¸¦é‡è¯•çš„è¿æ¥ï¼Œæˆ–è€…ä½¿ç”¨å…¨å±€sessioné…åˆé”)
    # *æ›´ä¼˜è§£*ï¼šåœ¨ ThreadPool é‡Œï¼Œrequests ä¼šè‡ªåŠ¨ç®¡ç†è¿æ¥æ± ã€‚æˆ‘ä»¬ç›´æ¥ä¼  session è¿›å»ã€‚
    
    global_session = get_session() 

    # with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
    #     future_to_id = {executor.submit(process_item, item, global_session): item['id'] for item in tasks}
        
    #     # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦
    #     pbar = tqdm(as_completed(future_to_id), total=len(tasks), unit="img")
        
        # for future in pbar:
        #     res = future.result()
            
        #     # ç»Ÿè®¡ç»“æœ
        #     if res == "Success":
        #         stats["Success"] += 1
        #     elif res == "Skipped":
        #         stats["Skipped"] += 1
        #     else:
        #         stats["Failed"] += 1
        #         # è®°å½•å…·ä½“é”™è¯¯åŸå› 
        #         err_type = res.split('_')[0]
        #         stats["Errors"][err_type] = stats["Errors"].get(err_type, 0) + 1

        # === æ–°å¢ï¼šå‡†å¤‡ä¸€ä¸ªæ–‡ä»¶æ¥è®°å½•å¤±è´¥çš„ID ===
    failed_log_file = open(r"F:\civitai_new_fetch\summary\failed_records.txt", "a", encoding="utf-8")

    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä¿å­˜äº†å®Œæ•´çš„ item è€Œä¸ä»…ä»…æ˜¯ idï¼Œæ–¹ä¾¿è·å– URL
        future_to_item = {executor.submit(process_item, item, global_session): item for item in tasks}
        
        pbar = tqdm(as_completed(future_to_item), total=len(tasks), unit="img")
        
        for future in pbar:
            # è·å–å½“å‰ä»»åŠ¡å¯¹åº”çš„åŸå§‹æ•°æ®
            current_item = future_to_item[future]
            current_id = current_item['id']
            current_url = current_item.get('url', 'No URL')

            try:
                res = future.result()
            except Exception as e:
                res = f"Exception_{str(e)}"

            # ç»Ÿè®¡ç»“æœ
            if res == "Success":
                stats["Success"] += 1
            elif res == "Skipped":
                stats["Skipped"] += 1
            else:
                # === ğŸ”´ å¤±è´¥å¤„ç†é€»è¾‘åœ¨è¿™é‡Œ ===
                stats["Failed"] += 1
                
                # 1. æ‰“å°åˆ°æ§åˆ¶å° (åŠ  \n é˜²æ­¢æ‰“æ–­è¿›åº¦æ¡)
                tqdm.write(f"âŒ å¤±è´¥ [ID: {current_id}] åŸå› : {res} | URL: {current_url}")
                
                # 2. å†™å…¥æ—¥å¿—æ–‡ä»¶ (ID, URL, åŸå› )
                failed_log_file.write(f"{current_id},{current_url},{res}\n")
                failed_log_file.flush()  # ç«‹å³å†™å…¥ï¼Œé˜²æ­¢ç¨‹åºå´©æºƒä¸¢å¤±
                
                # è®°å½•å…·ä½“é”™è¯¯åŸå› 
                err_type = res.split('_')[0]
                stats["Errors"][err_type] = stats["Errors"].get(err_type, 0) + 1
            
            pbar.set_postfix(fail=stats["Failed"], err=list(stats["Errors"].items())[:2])

        # è®°å¾—å…³é—­æ–‡ä»¶
        failed_log_file.close() 
            # åŠ¨æ€æ›´æ–°è¿›åº¦æ¡åç¼€ï¼Œæ˜¾ç¤ºå½“å‰å¤±è´¥ç‡
            # pbar.set_postfix(fail=stats["Failed"], err=list(stats["Errors"].items())[:2])

    print("\n" + "="*30)
    print(f"ğŸ“¥ æˆåŠŸ: {stats['Success']}")
    print(f"â­ï¸ è·³è¿‡: {stats['Skipped']}")
    print(f"âŒ å¤±è´¥: {stats['Failed']}")
    print("âš ï¸ é”™è¯¯è¯¦æƒ…:")
    for k, v in stats["Errors"].items():
        print(f"   - {k}: {v}")
    print("="*30)

if __name__ == "__main__":
    main()