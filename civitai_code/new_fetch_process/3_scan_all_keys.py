import json
import csv
from collections import Counter

def get_keys_recursively(data, parent_key=""):
    """
    é€’å½’æå–å­—å…¸ä¸­çš„æ‰€æœ‰é”®ã€‚
    å¯¹äºåˆ—è¡¨ï¼Œä¼šæ·»åŠ  [] æ ‡è®°ï¼Œå¹¶ç»§ç»­è¿›å…¥åˆ—è¡¨å†…éƒ¨æ‰«æã€‚
    """
    keys = []
    
    if isinstance(data, dict):
        for k, v in data.items():
            # æ„å»ºå½“å‰çš„å®Œæ•´è·¯å¾„ï¼Œä¾‹å¦‚ meta.resources
            current_path = f"{parent_key}.{k}" if parent_key else k
            keys.append(current_path)
            
            # é€’å½’æ·±å…¥ä¸‹ä¸€å±‚
            keys.extend(get_keys_recursively(v, current_path))
            
    elif isinstance(data, list):
        # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œæˆ‘ä»¬åœ¨è·¯å¾„ååŠ ä¸Š [] è¡¨ç¤ºè¿™æ˜¯ä¸ªæ•°ç»„
        # å¹¶ä¸”æ‰«æåˆ—è¡¨é‡Œçš„æ¯ä¸€ä¸ªå…ƒç´ ï¼ˆé€šå¸¸å–ç¬¬ä¸€ä¸ªéç©ºå…ƒç´ å°±å¤Ÿï¼Œä½†ä¸ºäº†ä¿é™©æˆ‘ä»¬æ‰«ææ‰€æœ‰ï¼‰
        list_path = f"{parent_key}[]"
        for item in data:
            keys.extend(get_keys_recursively(item, list_path))
            
    return keys

def scan_jsonl_structure(jsonl_file, output_csv):
    print(f"ğŸ•µï¸â€â™€ï¸ å¼€å§‹å…¨é‡æ‰«ææ–‡ä»¶: {jsonl_file} ...")
    
    # ä½¿ç”¨ Counter æ¥ç»Ÿè®¡æ¯ä¸ªé”®å‡ºç°äº†å¤šå°‘æ¬¡
    # è¿™èƒ½å¸®ä½ åŒºåˆ†å“ªäº›æ˜¯â€œæ ¸å¿ƒå­—æ®µâ€ï¼ˆå‡ºç°ç‡100%ï¼‰ï¼Œå“ªäº›æ˜¯â€œç¨€æœ‰å­—æ®µâ€
    key_counter = Counter()
    total_lines = 0
    
    try:
        with open(jsonl_file, 'r', encoding='utf-8') as infile:
            for line in infile:
                line = line.strip()
                if not line: continue
                
                try:
                    data = json.loads(line)
                    total_lines += 1
                    
                    # è·å–è¿™ä¸€è¡Œæ•°æ®é‡Œæ‰€æœ‰çš„é”®è·¯å¾„
                    paths = get_keys_recursively(data)
                    
                    # æ›´æ–°ç»Ÿè®¡
                    key_counter.update(set(paths)) # ä½¿ç”¨ set å»é‡ï¼Œç¡®ä¿ä¸€è¡Œæ•°æ®é‡ŒåŒä¸€ä¸ªé”®åªç®—ä¸€æ¬¡
                    
                    if total_lines % 1000 == 0:
                        print(f"å·²æ‰«æ {total_lines} è¡Œ...")
                        
                except json.JSONDecodeError:
                    continue

        # --- å¯¼å‡ºç»“æœ ---
        print(f"âœ… æ‰«æå®Œæˆï¼å…±åˆ†æ {total_lines} æ¡æ•°æ®ã€‚")
        print(f"æ­£åœ¨å†™å…¥ç»“æœåˆ° {output_csv} ...")
        
        with open(output_csv, 'w', newline='', encoding='utf-8-sig') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(['Key_Path', 'Count', 'Coverage_Rate (%)']) # è¡¨å¤´
            
            # æŒ‰å‡ºç°é¢‘ç‡ä»é«˜åˆ°ä½æ’åº
            for key, count in key_counter.most_common():
                coverage = (count / total_lines) * 100 if total_lines > 0 else 0
                writer.writerow([key, count, f"{coverage:.2f}%"])
                
        print(f"ğŸ“„ ç»“æœå·²ç”Ÿæˆï¼è¯·æŸ¥çœ‹: {output_csv}")

    except FileNotFoundError:
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {jsonl_file}")

# ==========================================
# è¿è¡Œè®¾ç½®
# ==========================================
if __name__ == "__main__":
    # è¾“å…¥æ–‡ä»¶å
    input_file = r"F:\civitai_new_fetch\summary\merged_only_images.jsonl" 
    # è¾“å‡ºæ–‡ä»¶å
    output_file = r"F:\civitai_new_fetch\summary\all_keys_report.csv"
    
    scan_jsonl_structure(input_file, output_file)